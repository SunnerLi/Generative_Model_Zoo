# --- Setting for StyleGAN optimizer ---
#
# Differ to paper, we alter to use AdamW because of attention block in UNet2DModel
# Adam with GAN + UNet2DModel would fail to train
optimizer_cls: torch.optim.AdamW
betas: [0.0, 0.999]
lr_g: 0.0001  # Original is 0.0002. Set as 0.0001 for small model
lr_d: 0.0001  # Original is 0.0002. Set as 0.0001 for small model
weight_decay: 0.01